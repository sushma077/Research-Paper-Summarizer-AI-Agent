{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages"
      ],
      "metadata": {
        "id": "-DLXpVlC5ns2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie0x1GBxr2GN",
        "outputId": "9fd0d177-45fd-4efc-f2f1-e0472afc2dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.0)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-1.0.0-py3-none-any.whl (27 kB)\n",
            "Downloading langchain_core-1.0.2-py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, pydeck, langgraph-sdk, langchain-core, streamlit, langgraph-checkpoint, langchain_huggingface, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.2 langchain_huggingface-1.0.0 langgraph-1.0.2 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.11.0 pydeck-0.9.1 streamlit-1.51.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit langgraph langchain_huggingface transformers peft datasets torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMX9ip9X9Q4p",
        "outputId": "00750e56-e13e-4c23-e577-8aa450bd9577"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.10.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3459861dc98423fcd1e74b275d2750940ccc167b5e44bad2298405c4b8ccc1f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score, bert-score\n",
            "Successfully installed bert-score-0.3.13 rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXARQ8APsCZA",
        "outputId": "607acdb7-f7ce-4da8-942b-20be2a8a3166"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n"
      ],
      "metadata": {
        "id": "EWdU9FJj5ybW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "from typing import TypedDict, Dict, List\n",
        "import requests\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "zVuetR64wSUL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score"
      ],
      "metadata": {
        "id": "XSsmVEhHwio1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL INITIALIZATION"
      ],
      "metadata": {
        "id": "0FFmeWlt53HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_llm(api_key: str):\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = api_key\n",
        "    llm = HuggingFaceEndpoint(\n",
        "        endpoint_url=\"openai/gpt-oss-120b\",\n",
        "        task=\"text-generation\",\n",
        "        huggingfacehub_api_token=api_key\n",
        "    )\n",
        "    return ChatHuggingFace(llm=llm)\n",
        "\n",
        "\n",
        "# STATE STRUCTURE\n",
        "class PaperInfo(TypedDict):\n",
        "    prompt: str\n",
        "    topic: List[str]\n",
        "    top_search: int\n",
        "    title: List[str]\n",
        "    abstract: List[str]\n",
        "    url: List[str]\n",
        "    citationCount: List[int]\n",
        "    result: str\n",
        "    model: object"
      ],
      "metadata": {
        "id": "auEWfAY8wimP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TITLE GENERATION\n"
      ],
      "metadata": {
        "id": "LP6iziZc6A07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_titles(Info: PaperInfo) -> PaperInfo:\n",
        "    base_topic = Info['prompt']\n",
        "    prompt = f\"\"\"\n",
        "Generate exactly {Info['top_search']} unique research paper title ideas\n",
        "that are all directly related to the topic: \"{base_topic}\".\n",
        "Each title must be academic-sounding and focused on different\n",
        "aspects (methods, challenges, applications, or improvements)\n",
        "within this same topic.\n",
        "Format each title as:\n",
        "1. Title text\n",
        "2. Title text\n",
        "and so on.\n",
        "    \"\"\"\n",
        "    response = Info['model'].invoke(prompt)\n",
        "    text = response.content\n",
        "\n",
        "    titles = [re.sub(r'^\\d+\\.\\s*', '', line).strip() for line in text.split('\\n') if line.strip()]\n",
        "    titles = [t for t in titles if len(t) > 3][:Info['top_search']]\n",
        "    Info['topic'] = titles\n",
        "    return Info"
      ],
      "metadata": {
        "id": "IYGKpvVMwijE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PAPER FETCH\n"
      ],
      "metadata": {
        "id": "MXhDYZVj6D_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_papers(Info: PaperInfo) -> PaperInfo:\n",
        "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "    main_topic = Info['prompt']\n",
        "\n",
        "    for i in range(min(Info['top_search'], len(Info['topic']))):\n",
        "        search_query = f\"{main_topic} {Info['topic'][i]}\"\n",
        "        params = {\n",
        "            \"query\": search_query,\n",
        "            \"fields\": \"title,url,abstract,citationCount\",\n",
        "            \"limit\": 1,\n",
        "            \"offset\": 0\n",
        "        }\n",
        "        response = requests.get(url, params=params)\n",
        "        data = response.json()\n",
        "\n",
        "        for paper in data.get(\"data\", []):\n",
        "            Info[\"abstract\"].append(paper.get(\"abstract\"))\n",
        "            Info[\"title\"].append(paper.get(\"title\"))\n",
        "            Info[\"url\"].append(paper.get(\"url\"))\n",
        "            Info[\"citationCount\"].append(paper.get(\"citationCount\"))\n",
        "    return Info"
      ],
      "metadata": {
        "id": "lVueoRuSwigW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SUMMARIZATION\n"
      ],
      "metadata": {
        "id": "QK2ueDen6HaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draft_answer(Info: PaperInfo) -> PaperInfo:\n",
        "    prompt = f\"\"\"Using the following research papers, create a detailed summary for each paper on the topic '{Info['prompt']}'.\n",
        "Each summary should be around 150 words, clearly explaining the paper's purpose, methods, and key findings.\n",
        "\n",
        "\"\"\"\n",
        "    for i in range(len(Info['title'])):\n",
        "        prompt += f\"Title: {Info['title'][i]}\\n\"\n",
        "        prompt += f\"Abstract: {Info['abstract'][i]}\\n\"\n",
        "        prompt += f\"URL: {Info['url'][i]}\\n\"\n",
        "        prompt += f\"Citations: {Info['citationCount'][i]}\\n\\n\"\n",
        "    prompt += \"Now write a detailed 150-word summary for each paper.\\nFormat:\\nTitle:\\nCitations:\\nAbstract Summary (~200 words):\\nURL:\\n\"\n",
        "\n",
        "    if hasattr(Info['model'], 'invoke'):\n",
        "        response = Info['model'].invoke(prompt)\n",
        "        Info['result'] = response.content\n",
        "    else:\n",
        "        tokenizer = Info['model'].tokenizer\n",
        "        model = Info['model'].model\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=400, temperature=0.7)\n",
        "        Info['result'] = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return Info"
      ],
      "metadata": {
        "id": "lR7UxXUzwidX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRAPH SETUP\n"
      ],
      "metadata": {
        "id": "BPd5-5J86KrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(PaperInfo)\n",
        "graph.add_node(\"generate_titles\", generate_titles)\n",
        "graph.add_node(\"get_papers\", get_papers)\n",
        "graph.add_node(\"draft_answer\", draft_answer)\n",
        "graph.add_edge(START, \"generate_titles\")\n",
        "graph.add_edge(\"generate_titles\", \"get_papers\")\n",
        "graph.add_edge(\"get_papers\", \"draft_answer\")\n",
        "graph.add_edge(\"draft_answer\", END)\n",
        "research_paper_graph = graph.compile()"
      ],
      "metadata": {
        "id": "6OLO9jEpwiWD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINE-TUNING\n"
      ],
      "metadata": {
        "id": "Cx_xzE-n6N24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(base_model=\"google/flan-t5-base\", dataset_name=\"scientific_papers\", output_dir=\"./finetuned_model\"):\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(dataset_name, \"pubmed\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(base_model)\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\"q\", \"v\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"SEQ_2_SEQ_LM\"\n",
        "    )\n",
        "    model = get_peft_model(model, lora_config)\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n",
        "        model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            labels = tokenizer(examples[\"abstract\"], max_length=150, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        learning_rate=2e-4,\n",
        "        per_device_train_batch_size=2,\n",
        "        num_train_epochs=1,\n",
        "        weight_decay=0.01,\n",
        "        save_total_limit=1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"].select(range(1000)),\n",
        "        eval_dataset=tokenized_datasets[\"validation\"].select(range(200)),\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    print(\"Fine-tuning complete. Model saved at\", output_dir)\n",
        "    return output_dir"
      ],
      "metadata": {
        "id": "KWHA4Djrwia-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD FINE-TUNED MODEL\n",
        "def load_finetuned_model(path: str):\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "    class FineTunedModel:\n",
        "        def invoke(self, text):\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "            outputs = model.generate(**inputs, max_length=200)\n",
        "            result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            return type(\"Response\", (), {\"content\": result})\n",
        "\n",
        "    return FineTunedModel()"
      ],
      "metadata": {
        "id": "70LpW1pWwiYe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rationale for Choosing Fine-Tuning Target\n",
        "\n",
        "**Model:** google/flan-t5-base\n",
        "\n",
        "**Method:** LoRA fine-tuning\n",
        "\n",
        "**Dataset:** Scientific Papers (PubMed subset)\n",
        "\n",
        "The base model, Flan-T5, performs well on general summarization but lacks domain knowledge for technical research papers. Fine-tuning it on PubMed abstracts helps the model learn academic structure, terminology, and factual summarization style.\n",
        "\n",
        "This setup ensures the model:\n",
        "\n",
        "* Focuses on **key findings and methods** instead of surface-level details.\n",
        "* Writes in a **formal, research-oriented tone**.\n",
        "* Achieves higher **accuracy and coherence** in summaries.\n",
        "\n",
        "LoRA is used for efficiency, as it updates only small parameter sets—saving compute while maintaining quality.\n",
        "Overall, this approach creates a lightweight, domain-adapted model optimized for **scientific paper summarization** tasks.\n"
      ],
      "metadata": {
        "id": "F_RL2Ebx33IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION FUNCTION"
      ],
      "metadata": {
        "id": "kMHF5UGp6TeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summary(generated_summary: str, reference_text: str):\n",
        "    \"\"\"\n",
        "    Computes ROUGE and BERTScore metrics between generated and reference summaries.\n",
        "    \"\"\"\n",
        "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = rouge.score(reference_text, generated_summary)\n",
        "\n",
        "    P, R, F1 = bert_score([generated_summary], [reference_text], lang=\"en\", verbose=False)\n",
        "    bert = {\n",
        "        \"Precision\": P.mean().item(),\n",
        "        \"Recall\": R.mean().item(),\n",
        "        \"F1\": F1.mean().item()\n",
        "    }\n",
        "\n",
        "    return {\"ROUGE\": rouge_scores, \"BERTScore\": bert}\n"
      ],
      "metadata": {
        "id": "2bCxXE5FwiTm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAIN EXECUTION\n"
      ],
      "metadata": {
        "id": "c7068TK06V8k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XF_iGumtwSNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    api_key = \"key\"\n",
        "    use_finetuned = False  # Toggle True to use your LoRA fine-tuned model\n",
        "\n",
        "    if use_finetuned:\n",
        "        model = load_finetuned_model(\"./finetuned_model\")\n",
        "    else:\n",
        "        model = initialize_llm(api_key)\n",
        "\n",
        "    topic = input(\"Enter your research topic: \").strip()\n",
        "    top_n = int(input(\"Enter how many papers to summarize (e.g., 3): \"))\n",
        "\n",
        "    initial_info: PaperInfo = {\n",
        "        \"prompt\": topic,\n",
        "        \"topic\": [],\n",
        "        \"top_search\": top_n,\n",
        "        \"title\": [],\n",
        "        \"abstract\": [],\n",
        "        \"url\": [],\n",
        "        \"citationCount\": [],\n",
        "        \"result\": \"\",\n",
        "        \"model\": model,\n",
        "    }\n",
        "\n",
        "    result = research_paper_graph.invoke(initial_info)\n",
        "\n",
        "    print(\"\\n\\nSUMMARIZED RESULT\")\n",
        "    safe_output = result[\"result\"].encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "    print(safe_output)\n",
        "\n",
        "\n",
        "    print(\"\\n\\nEVALUATION METRICS\")\n",
        "    reference_text = input(\"\\nEnter reference text (true summary for evaluation):\\n\")\n",
        "    metrics = evaluate_summary(safe_output, reference_text)\n",
        "    print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e29f46-4fb7-414f-d59f-aaeda961bc13",
        "id": "UpHj1t5hMEvu"
      },
      "execution_count": 39,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your research topic: Transformers in Machine Learning\n",
            "Enter how many papers to summarize (e.g., 3): 3\n",
            "\n",
            "\n",
            "SUMMARIZED RESULT\n",
            "**Title:** Attention Is All You Need  \n",
            "**Citations:** Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). *Advances in Neural Information Processing Systems*, 30.  \n",
            "**Abstract Summary (~150‑200 words):**  \n",
            "This seminal work introduces the Transformer architecture, which dispenses with recurrence and convolution in favor of a pure attention mechanism. The authors propose multi‑head self‑attention to capture relationships between all token pairs in a sequence, coupled with position‑wise feed‑forward networks, residual connections, and layer normalization. Positional encodings inject order information. By stacking encoder and decoder blocks, the model achieves state‑of‑the‑art results on machine translation benchmarks (WMT 2014 English‑German and English‑French) while dramatically reducing training time compared with recurrent models. The paper also presents a detailed analysis of computational complexity, showing that self‑attention scales quadratically with sequence length but is highly parallelizable on GPUs. Ablation studies confirm the importance of multi‑head attention and positional encodings. The Transformer set the foundation for subsequent large‑scale language models and cross‑modal architectures.  \n",
            "**URL:** https://arxiv.org/abs/1706.03762  \n",
            "\n",
            "---\n",
            "\n",
            "**Title:** BERT: Pre‑training of Deep Bidirectional Transformers for Language Understanding  \n",
            "**Citations:** Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). *Proceedings of NAACL‑HLT*.  \n",
            "**Abstract Summary (~150‑200 words):**  \n",
            "BERT (Bidirectional Encoder Representations from Transformers) advances NLP by pre‑training deep bidirectional Transformers on massive unlabeled corpora using two novel objectives: Masked Language Modeling (MLM) and Next Sentence Prediction (NSP). Unlike previous left‑to‑right models, BERT’s masked tokens enable the encoder to incorporate both left and right contexts simultaneously. After pre‑training on BooksCorpus and English Wikipedia, the model is fine‑tuned with a single additional output layer for a wide range of downstream tasks (question answering, sentiment analysis, natural language inference). Empirically, BERT‑base (12 layers) and BERT‑large (24 layers) achieve state‑of‑the‑art results on the GLUE benchmark, SQuAD v1.1/v2.0, and SWAG, often surpassing prior systems by large margins. The paper highlights the simplicity of the fine‑tuning procedure and demonstrates that a single pre‑trained model can be adapted to many tasks with minimal architecture changes.  \n",
            "**URL:** https://arxiv.org/abs/1810.04805  \n",
            "\n",
            "---\n",
            "\n",
            "**Title:** Vision Transformer (ViT): An Image is Worth 16×16 Words  \n",
            "**Citations:** Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., … & Houlsby, N. (2021). *International Conference on Learning Representations (ICLR)*.  \n",
            "**Abstract Summary (~150‑200 words):**  \n",
            "ViT adapts the Transformer architecture to image recognition by treating an image as a sequence of flattened, non‑overlapping patches (e.g., 16×16 pixels) linearly embedded into vectors and supplemented with positional embeddings. The authors demonstrate that, when trained on large‑scale datasets (e.g., ImageNet‑21k, JFT‑300M), ViT matches or exceeds the performance of state‑of‑the‑art convolutional networks while requiring far fewer FLOPs at inference. Crucially, the model scales effectively with depth, width, and training data volume, highlighting the importance of massive pre‑training. Experiments include ablations on patch size, data augmentation, and hybrid CNN‑Transformer designs. ViT also transfers well to downstream tasks such as object detection and segmentation when fine‑tuned. The work establishes that pure self‑attention, devoid of convolutions, can serve as a universal backbone for vision, opening avenues for unified multimodal models.  \n",
            "**URL:** https://arxiv.org/abs/2010.11929  \n",
            "\n",
            "---\n",
            "\n",
            "**Title:** Language Models are Few‑Shot Learners (GPT‑3)  \n",
            "**Citations:** Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., … & Amodei, D. (2020). *Advances in Neural Information Processing Systems*, 33.  \n",
            "**Abstract Summary (~150‑200 words):**  \n",
            "GPT‑3 investigates the scaling behavior of autoregressive language models by training a 175 billion‑parameter Transformer on a diverse 570 GB text corpus. The study finds that performance on a wide range of NLP tasks improves smoothly with model size, data, and compute, eventually enabling strong few‑shot learning: the model can adapt to new tasks from only a handful of natural‑language examples without gradient updates. Prompt engineering is used to convey task instructions, demonstrations, or examples. GPT‑3 attains competitive results on benchmarks such as translation, question answering, cloze tests, and even code generation, often rivaling specialized fine‑tuned models. The authors analyze emergent abilities, discuss limitations (biases, calibration, and reliability), and propose scaling as a viable path toward more general AI systems. This work underscores the power of large‑scale Transformers and reshapes how researchers think about model training versus task‑specific fine‑tuning.  \n",
            "**URL:** https://arxiv.org/abs/2005.14165  \n",
            "\n",
            "---\n",
            "\n",
            "**Title:** Transformer‑XL: Attentive Language Models Beyond a Fixed‑Length Context  \n",
            "**Citations:** Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., & Salakhutdinov, R. (2019). *Proceedings of ACL*.  \n",
            "**Abstract Summary (~150‑200 words):**  \n",
            "Transformer‑XL introduces a recurrence mechanism that enables Transformers to capture dependencies beyond a fixed context length, a limitation of the original architecture. By caching hidden states from previous segments and reusing them as additional context for subsequent segments, the model maintains a continuous representation across arbitrarily long sequences while preserving the parallelizability of self‑attention. A novel relative positional encoding scheme mitigates the mismatch between cached and current positions. Empirically, Transformer‑XL achieves state‑of‑the‑art perplexities on language modeling datasets such as WikiText‑103, en‑wik8, and text8, surpassing both recurrent and standard Transformer baselines. Analyses reveal that the model learns longer‑range syntactic and semantic patterns, improving downstream tasks like text classification and generation. The paper demonstrates that the recurrence‑plus‑attention design is a practical and scalable solution for modeling long‑range structure in sequential data.  \n",
            "**URL:** https://arxiv.org/abs/1901.02860\n",
            "\n",
            "\n",
            "EVALUATION METRICS\n",
            "\n",
            "Enter reference text (true summary for evaluation):\n",
            "Transformers have revolutionized the field of deep learning by introducing a new architecture that relies entirely on attention mechanisms, eliminating the need for recurrent or convolutional structures traditionally used for sequence modeling. Introduced by Vaswani et al. in the landmark 2017 paper *“Attention Is All You Need,”* transformers enable models to process entire sequences in parallel, significantly improving training efficiency and scalability. The core idea behind transformers is the self-attention mechanism, which allows the model to weigh the importance of different words or tokens relative to one another, capturing long-range dependencies more effectively than RNNs or LSTMs. This innovation led to the development of large pre-trained language models such as BERT, GPT, and T5, which have set new benchmarks in natural language understanding and generation tasks. Beyond text, the transformer architecture has been successfully adapted to other domains, including computer vision (Vision Transformers or ViTs), audio processing, and even multimodal tasks that combine language and vision. Current research on transformers focuses on improving their efficiency, interpretability, and adaptability through techniques like sparse attention, knowledge distillation, and parameter-efficient fine-tuning methods such as LoRA and adapters. As transformer-based models continue to scale in size and capability, they are reshaping the landscape of artificial intelligence, powering state-of-the-art systems in translation, summarization, image recognition, and scientific discovery.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ROUGE': {'rouge1': Score(precision=0.17096774193548386, recall=0.7162162162162162, fmeasure=0.2760416666666667), 'rouge2': Score(precision=0.03336921420882669, recall=0.14027149321266968, fmeasure=0.05391304347826087), 'rougeL': Score(precision=0.06451612903225806, recall=0.2702702702702703, fmeasure=0.10416666666666666)}, 'BERTScore': {'Precision': 0.7817198038101196, 'Recall': 0.8515523672103882, 'F1': 0.8151431679725647}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_6Xmt9LwSLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4PJbwEsVWrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1R2dhuHbbfZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wABpsMofbfV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WuUSmw85wSGK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}